import torch
import torch.nn as nn
import math
from torch.autograd import Variable


class SelfAttention(nn.Module):
    def __init__(self, dimension_input, d):
        super(SelfAttention, self).__init__()
        self.dimension_input = dimension_input
        self.d = d # d is the dimension of transformed space
        # The following two rows are linear layers that represents the matrices that map the input to 'queries' and 'keys' components
        self.FC_q = nn.Linear(self.dimension_input, self.d)
        self.FC_k = nn.Linear(self.dimension_input, self.d)
        self.eval()

    def forward(self, X):
        patches_number, d_in = X.size()
        X = X.float()
        queries = self.FC_q(X) # Compute the query projection that create the queries matrix of size (N, d)
        keys = self.FC_k(X) # Compute the Key projection that create the keys matrix of size (N, d)
        transposed_queries = torch.einsum('ij->ji', [queries])
        attention_matrix = torch.einsum('ik,kj->ij', [keys, transposed_queries]) # Compute the attention matrix (N, N) between patches (dot product between the patches)
        attention_matrix = torch.div(attention_matrix, math.sqrt(d_in)) # Since the average value of the dot product grows with the vector’s dimension, each entry in the Key and Query matrices can be disproportionally too large if d_in is large. To counter this, the factor math.sqrt(d_in) is used to normalize the inputs.
        return attention_matrix

    def set_params(self, ler_parameters):
        '''This method sets the learnable parameters of the SelfAttention to the values of the 
        best candidate solution generated by CMA-ES at each iteration of the algorithm.'''
        self.FC_q.weight = nn.Parameter(torch.reshape(ler_parameters[:self.dimension_input * self.d], (self.d, self.dimension_input)))
        self.FC_k.weight = nn.Parameter(torch.reshape(ler_parameters[self.dimension_input * self.d:], (self.d, self.dimension_input)))

    def get_params(self):
        return self.FC_q.weight, self.FC_k.weight



class LSTMController(nn.Module):
    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length, L):
        super(LSTMController, self).__init__()
        self.num_classes = num_classes #number of classes
        self.num_layers = num_layers #number of layers
        self.input_size = input_size #input size
        self.hidden_size = hidden_size #hidden state
        self.seq_length = seq_length #sequence length
        self.L = L #observation size
        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size,
                          num_layers=self.num_layers, batch_first=True) #lstm
        self.fc_prev = nn.Linear(self.hidden_size, self.hidden_size) # fully connected linear layer 
        self.fc = nn.Linear(self.hidden_size, self.num_classes) #fully connected last layer
        self.relu = nn.ReLU()
        self.softmax = nn.Softmax(dim=1)
        self.reset()
        self.eval()

    def forward(self, x):
        x = x.float()
        # Propagate input through LSTM
        output, self.hidden = self.lstm(x, self.hidden) #lstm with input, hidden, and internal state
        output = output.view(-1, self.hidden_size) #reshaping the data for Dense layer next
        output = self.relu(self.fc_prev(output))
        output = self.fc(output)
        output = self.softmax(output)
        return output

    def reset(self):
        self.hidden = (Variable(torch.randn(self.num_layers, 1, self.hidden_size)), # this shape must be equals to the input x ,now it has shape (1,1,20).
                    Variable(torch.randn(self.num_layers, 1, self.hidden_size)),
        )

    def set_params(self, ler_parameters):
        """This method sets the learnable parameters of the LSTMController to the values of 
        the best candidate solution generated by CMA-ES at each iteration of the algorithm."""
        index_count = self.L * self.input_size
        self.lstm.weight_ih_l0 = nn.Parameter(torch.reshape(ler_parameters[:index_count], (self.L, self.input_size)))
        self.lstm.weight_hh_l0 = nn.Parameter(torch.reshape(ler_parameters[index_count:index_count + (self.L * self.hidden_size)], (self.L, self.hidden_size)))
        index_count += (self.L * self.hidden_size)
        self.lstm.bias_ih_l0 = nn.Parameter(ler_parameters[index_count:index_count + self.L])
        index_count += self.L
        self.lstm.bias_hh_l0 = nn.Parameter(ler_parameters[index_count:index_count + self.L])
        index_count += self.L
        
        ################################################
        self.fc_prev.weight = nn.Parameter(torch.reshape(ler_parameters[index_count:index_count + (self.hidden_size * self.hidden_size)], (self.hidden_size, self.hidden_size)))
        index_count += (self.hidden_size * self.hidden_size)
        self.fc_prev.bias = nn.Parameter(ler_parameters[index_count:index_count + self.hidden_size])
        index_count += self.hidden_size
        ################################################
        
        self.fc.weight = nn.Parameter(torch.reshape(ler_parameters[index_count:index_count + (self.num_classes * self.hidden_size)], (self.num_classes, self.hidden_size)))
        index_count += (self.num_classes * self.hidden_size)
        self.fc.bias = nn.Parameter(ler_parameters[index_count:])
